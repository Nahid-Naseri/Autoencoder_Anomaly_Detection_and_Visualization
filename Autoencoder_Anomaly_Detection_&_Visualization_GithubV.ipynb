{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpklqhXBFF_l",
        "outputId": "7f94dca7-aba6-4e36-c2ce-65274511096d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = '/content/drive/MyDrive/mvtec_project/metal_nut'\n",
        "train_dir = os.path.join(base_path, 'train', 'images')\n",
        "test_dir = os.path.join(base_path, 'test', 'images')\n",
        "\n",
        "print(\"Train directory:\", train_dir)\n",
        "print(\"Exists:\", os.path.exists(train_dir))\n",
        "print(\"Test directory:\", test_dir)\n",
        "print(\"Exists:\", os.path.exists(test_dir))"
      ],
      "metadata": {
        "id": "DtjgJ60BcmKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision matplotlib"
      ],
      "metadata": {
        "id": "h_zKudWbcpDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "test_normal_dir = '/content/drive/MyDrive/mvtec_project/metal_nut/test/images/normal'\n",
        "files = os.listdir(test_normal_dir) if os.path.exists(test_normal_dir) else []\n",
        "print(f\"Files in test 'normal' folder ({test_normal_dir}): {files[:10]}\")  # Show first 10 files or empty"
      ],
      "metadata": {
        "id": "QQBOWD0rcqFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def wrap_test_images(image_dir):\n",
        "    normal_dir = os.path.join(image_dir, 'normal')\n",
        "    if not os.path.exists(normal_dir):\n",
        "        os.makedirs(normal_dir)\n",
        "    for f in os.listdir(image_dir):\n",
        "        fpath = os.path.join(image_dir, f)\n",
        "        if os.path.isfile(fpath) and f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            shutil.move(fpath, os.path.join(normal_dir, f))\n",
        "\n",
        "wrap_test_images('/content/drive/MyDrive/mvtec_project/metal_nut/test/images')\n",
        "print(\"✅ Moved test images into 'normal' folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdJbf4nBIWlX",
        "outputId": "84e7aaa7-3d23-4fcd-dbe6-7e2753f9064f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Moved test images into 'normal' folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Set paths\n",
        "train_dir = '/content/drive/MyDrive/mvtec_project/metal_nut/train/images'\n",
        "test_dir = '/content/drive/MyDrive/mvtec_project/metal_nut/test/images'\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
        "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(f\"Train classes: {train_dataset.classes}\")\n",
        "print(f\"Train samples: {len(train_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ahf8_SV4XImq",
        "outputId": "1b73a858-ad47-49bd-b975-9d079744b22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train classes: ['normal']\n",
            "Train samples: 50\n",
            "Test samples: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step-by-Step Autoencoder-Based Anomaly Detection with Reconstruction Visualization"
      ],
      "metadata": {
        "id": "yRTFtPkGfZlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Autoencoder architecture\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, stride=2, padding=1),  # 64x64\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # 32x32\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1), # 16x16\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1), # 32x32\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # 64x64\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 3, 3, stride=2, padding=1, output_padding=1),  # 128x128\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "# Initialize model, loss, optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ConvAutoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 20\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Evaluate reconstruction error on test images\n",
        "model.eval()\n",
        "import numpy as np\n",
        "\n",
        "def plot_reconstructions(model, loader, num_images=5):\n",
        "    data_iter = iter(loader)\n",
        "    images, _ = next(data_iter)\n",
        "    images = images[:num_images].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(15, 4))\n",
        "    for i in range(num_images):\n",
        "        axes[0, i].imshow(images[i].cpu().permute(1, 2, 0))\n",
        "        axes[0, i].set_title(\"Original\")\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        axes[1, i].imshow(outputs[i].cpu().permute(1, 2, 0))\n",
        "        axes[1, i].set_title(\"Reconstructed\")\n",
        "        axes[1, i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_reconstructions(model, test_loader)"
      ],
      "metadata": {
        "id": "HVkpc7KAdD-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing Anomalies Using Error Heatmaps: Comparing Normal and Defective Images"
      ],
      "metadata": {
        "id": "Z_NLkurnfkzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Paths\n",
        "test_root = '/content/drive/MyDrive/mvtec_project/metal_nut/test'\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load test dataset (normal and defective)\n",
        "test_dataset = ImageFolder(root=test_root, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Class mapping\n",
        "print(\"Class to index:\", test_dataset.class_to_idx)\n",
        "\n",
        "# Autoencoder model (assume it's called 'model')\n",
        "model.eval()\n",
        "\n",
        "# Function to compute heatmap\n",
        "def show_anomaly(original, reconstructed):\n",
        "    error = torch.abs(original - reconstructed).squeeze().detach().cpu().numpy()\n",
        "    heatmap = np.mean(error, axis=0)  # mean over channels\n",
        "    return heatmap\n",
        "\n",
        "# Visualize few results\n",
        "for i, (img, label) in enumerate(test_loader):\n",
        "    if i >= 5: break  # just show 5 images\n",
        "\n",
        "    img = img.to(device)\n",
        "    with torch.no_grad():\n",
        "        reconstructed = model(img)\n",
        "\n",
        "    heatmap = show_anomaly(img, reconstructed)\n",
        "\n",
        "    # Convert to numpy for plotting\n",
        "    original_np = img.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "    reconstructed_np = reconstructed.squeeze().permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # Plot\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    axs[0].imshow(original_np)\n",
        "    axs[0].set_title(\"Original\")\n",
        "    axs[1].imshow(reconstructed_np)\n",
        "    axs[1].set_title(\"Reconstructed\")\n",
        "    axs[2].imshow(heatmap, cmap='hot')\n",
        "    axs[2].set_title(\"Anomaly Heatmap\")\n",
        "    for ax in axs: ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "G1zpcYZWdMkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# Make sure your model and device are defined\n",
        "model.eval()\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/mvtec_project/results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def calculate_threshold(errors, k=3):\n",
        "    mean = np.mean(errors)\n",
        "    std = np.std(errors)\n",
        "    return mean + k * std\n",
        "\n",
        "anomaly_scores = []\n",
        "labels = []\n",
        "\n",
        "for i, (img, label) in enumerate(test_loader):\n",
        "    img = img.to(device)\n",
        "    with torch.no_grad():\n",
        "        reconstructed = model(img)\n",
        "\n",
        "    error_map = (img - reconstructed) ** 2\n",
        "    error_score = error_map.mean().item()\n",
        "\n",
        "    anomaly_scores.append(error_score)\n",
        "    labels.append(label.item())\n",
        "\n",
        "    # Save images\n",
        "    save_image(img.cpu(), os.path.join(output_dir, f'{i}_original.png'))\n",
        "    save_image(reconstructed.cpu(), os.path.join(output_dir, f'{i}_reconstructed.png'))\n",
        "\n",
        "    heatmap = error_map.squeeze().mean(dim=0).cpu().numpy()\n",
        "    plt.imshow(heatmap, cmap='hot')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Error Heatmap (Score: {error_score:.4f})')\n",
        "    plt.savefig(os.path.join(output_dir, f'{i}_heatmap.png'))\n",
        "    plt.close()\n",
        "\n",
        "print(f\"Saved results to {output_dir}\")\n",
        "\n",
        "# Calculate threshold from normal images\n",
        "normal_class_idx = test_dataset.class_to_idx['normal']\n",
        "normal_scores = np.array(anomaly_scores)[np.array(labels) == normal_class_idx]\n",
        "threshold = calculate_threshold(normal_scores, k=3)\n",
        "print(f\"Anomaly score threshold: {threshold:.4f}\")\n",
        "\n",
        "# Predict anomalies\n",
        "predicted = np.array(anomaly_scores) > threshold\n",
        "true_labels = np.array(labels) != normal_class_idx  # normal=0, defective=1 (currently you only have normal, so all 0)\n",
        "\n",
        "# Accuracy calculation (won't be meaningful until you add defective images)\n",
        "accuracy = (predicted == true_labels).mean()\n",
        "print(f\"Anomaly detection accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jOJbJxLirUh",
        "outputId": "6439ef42-e4f3-4317-d346-a17125bbba53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to /content/drive/MyDrive/mvtec_project/results\n",
            "Anomaly score threshold: 0.0093\n",
            "Anomaly detection accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/MyDrive/mvtec_project/autoencoder_model.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAfiwpfxja9R",
        "outputId": "febae41e-2a78-4665-9021-c9ba85205825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/MyDrive/mvtec_project/autoencoder_model.pth\n"
          ]
        }
      ]
    }
  ]
}